{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5, Question 6: Data Transformation\n",
    "\n",
    "**Points: 20**\n",
    "\n",
    "Transform and engineer features from the clinical trial dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run test on q3_data cleanup...\n",
      "Test DataFrame created: (5, 2)\n",
      "Test detect_missing: 1\n",
      "Test passed!\n",
      "Loaded 10000 patients\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import utilities\n",
    "from q3_data_utils import load_data, clean_data, transform_types, create_bins, fill_missing\n",
    "\n",
    "df = load_data('data/clinical_trial_raw.csv')\n",
    "print(f\"Loaded {len(df)} patients\")\n",
    "\n",
    "# Prewritten visualization functions for transformation analysis\n",
    "def plot_distribution(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a histogram of a numeric series.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with numeric data\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.hist(bins=30)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_value_counts(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a bar chart of value counts.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with value counts\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.plot(kind='bar')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Type Conversions (5 points)\n",
    "\n",
    "1. Convert 'enrollment_date' to datetime using the `transform_types()` utility\n",
    "2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "3. Ensure all numeric columns are proper numeric types\n",
    "4. Display the updated dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Data types before transformation:\n",
      "============================================================\n",
      "\n",
      "1. Converting enrollment_date to datetime...\n",
      "Warning: Column 'enrollment_date' not found in DataFrame.\n",
      " enrollment_date converted to datetime\n",
      "\n",
      "2. Converting categorical columns to category type...\n",
      "Warning: Column 'site' not found in DataFrame.\n",
      "Warning: Column 'intervention_group' not found in DataFrame.\n",
      "Warning: Column 'sex' not found in DataFrame.\n",
      " Categorical columns converted to category type\n",
      "\n",
      "3. Converting numeric columns to proper numeric type...\n",
      "Warning: Column 'age' not found in DataFrame.\n",
      "Warning: Column 'bmi' not found in DataFrame.\n",
      "Warning: Column 'weight' not found in DataFrame.\n",
      "Warning: Column 'height' not found in DataFrame.\n",
      "Warning: Column 'cholesterol_total' not found in DataFrame.\n",
      "Warning: Column 'systolic_bp' not found in DataFrame.\n",
      "Warning: Column 'diastolic_bp' not found in DataFrame.\n",
      " Numeric columns converted to proper numeric type\n",
      "\n",
      "4. Updated data types:\n",
      "patient_id             object\n",
      "age                     int64\n",
      "sex                    object\n",
      "bmi                   float64\n",
      "enrollment_date        object\n",
      "systolic_bp           float64\n",
      "diastolic_bp          float64\n",
      "cholesterol_total     float64\n",
      "cholesterol_hdl       float64\n",
      "cholesterol_ldl       float64\n",
      "glucose_fasting       float64\n",
      "site                   object\n",
      "intervention_group     object\n",
      "follow_up_months        int64\n",
      "adverse_events          int64\n",
      "outcome_cvd            object\n",
      "adherence_pct         float64\n",
      "dropout                object\n",
      "dtype: object\n",
      "\n",
      "Summary of type changes:\n",
      " Datetime columns: 0\n",
      " Categorical columns: 0\n",
      " Numeric columns: 11\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO: Type conversions\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Data types before transformation:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# 1. Use transform_types() to convert enrollment_date to datetime\n",
    "print(\"1. Converting enrollment_date to datetime...\")\n",
    "type_map = {'enrollment_date': 'datetime'}\n",
    "df_typed = transform_types(df, type_map)\n",
    "print(\" enrollment_date converted to datetime\")\n",
    "print()\n",
    "\n",
    "# 2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "print(\"2. Converting categorical columns to category type...\")\n",
    "categorical_cols = {\n",
    "    'site': 'category',\n",
    "    'intervention_group': 'category',\n",
    "    'sex': 'category'\n",
    "}\n",
    "df_typed = transform_types(df_typed, categorical_cols)\n",
    "print(\" Categorical columns converted to category type\")\n",
    "print()\n",
    "\n",
    "# 3. Ensure all numeric columns are proper numeric types\n",
    "print(\"3. Converting numeric columns to proper numeric type...\")\n",
    "numeric_map = {\n",
    "    'age': 'numeric',\n",
    "    'bmi': 'numeric',\n",
    "    'weight': 'numeric',\n",
    "    'height': 'numeric',\n",
    "    'cholesterol_total': 'numeric',\n",
    "    'systolic_bp': 'numeric',\n",
    "    'diastolic_bp': 'numeric'\n",
    "}\n",
    "df_typed = transform_types(df_typed, numeric_map)\n",
    "print(\" Numeric columns converted to proper numeric type\")\n",
    "print()\n",
    "\n",
    "# 4. Display the updated dtypes using df.dtypes\n",
    "print(\"4. Updated data types:\")\n",
    "print(df_typed.dtypes)\n",
    "print()\n",
    "\n",
    "\n",
    "# Summary of changes\n",
    "print(\"Summary of type changes:\")\n",
    "print(f\" Datetime columns: {(df_typed.dtypes == 'datetime64[ns]').sum()}\")\n",
    "print(f\" Categorical columns: {(df_typed.dtypes == 'category').sum()}\")\n",
    "print(f\" Numeric columns: {(df_typed.select_dtypes(include=[np.number]).shape[1])}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering (8 points)\n",
    "\n",
    "Create these new calculated columns:\n",
    "\n",
    "1. `cholesterol_ratio` = cholesterol_ldl / cholesterol_hdl\n",
    "2. `bp_category` = categorize systolic BP:\n",
    "   - 'Normal': < 120\n",
    "   - 'Elevated': 120-129\n",
    "   - 'High': >= 130\n",
    "3. `age_group` using `create_bins()` utility:\n",
    "   - Bins: [0, 40, 55, 70, 100]\n",
    "   - Labels: ['<40', '40-54', '55-69', '70+']\n",
    "4. `bmi_category` using standard BMI categories:\n",
    "   - Underweight: <18.5\n",
    "   - Normal: 18.5-24.9\n",
    "   - Overweight: 25-29.9\n",
    "   - Obese: >=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Creating cholesterol ratio column...\n",
      " Cholesterol ratio = cholesterol_ldl / cholesterol_hdl\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('cholesterol_ldl', 'cholesterol_hdl', 'cholesterol_ratio')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/UCSF MAS/DATASCI 217 Python/DATASCI217 Midterm/ds217-midterm-cshiu/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: ('cholesterol_ldl', 'cholesterol_hdl', 'cholesterol_ratio')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m df_typed[\u001b[33m'\u001b[39m\u001b[33mcholesterol_ratio\u001b[39m\u001b[33m'\u001b[39m] = df_typed[\u001b[33m'\u001b[39m\u001b[33mcholesterol_ldl\u001b[39m\u001b[33m'\u001b[39m] / df_typed[\u001b[33m'\u001b[39m\u001b[33mcholesterol_hdl\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m Cholesterol ratio = cholesterol_ldl / cholesterol_hdl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_typed\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcholesterol_ldl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcholesterol_hdl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcholesterol_ratio\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/UCSF MAS/DATASCI 217 Python/DATASCI217 Midterm/ds217-midterm-cshiu/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/UCSF MAS/DATASCI 217 Python/DATASCI217 Midterm/ds217-midterm-cshiu/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: ('cholesterol_ldl', 'cholesterol_hdl', 'cholesterol_ratio')"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate cholesterol ratio\n",
    "\n",
    "print(\"1. Creating cholesterol ratio column...\")\n",
    "df_typed['cholesterol_ratio'] = df_typed['cholesterol_ldl'] / df_typed['cholesterol_hdl']\n",
    "print(\" Cholesterol ratio = cholesterol_ldl / cholesterol_hdl\")\n",
    "print(df_typed['cholesterol_ldl', 'cholesterol_hdl', 'cholesterol_ratio'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Categorize blood pressure\n",
    "df_typed['bp_category'] = pd.cut(\n",
    "    df_typed['systolic_bp'],\n",
    "    bins=[0, 10, 130, float('inf')],\n",
    "    labels=['Normal', 'Elevated', 'High'],\n",
    "    right=False\n",
    ")\n",
    "print(\"2. BP categories created\")\n",
    "print(df_typed['systolic_bp', 'bp_category'].head(10))\n",
    "print()\n",
    "\n",
    "# ACtually, I like this better\n",
    "df_typed['bp_category'] = np.where(\n",
    "    df_typed['systolic_bp'] < 120, 'Normal',\n",
    "    np.where(\n",
    "        (df_typed['systolic_bp'] >= 120) & (df_typed['systolic_bp'] < 130), 'Elevated',\n",
    "        'High'\n",
    "    )\n",
    ")\n",
    "print(\"BP categories created\")\n",
    "print(df_typed[['systolic_bp', 'bp_category']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The `create_bins()` function has an optional `new_column` parameter. If you don't specify it, the new column will be named `{original_column}_binned`. You can use `new_column='age_group'` to give it a custom name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create age groups\n",
    "df_typed = create_bins(\n",
    "    df_typed,\n",
    "    column = 'age',\n",
    "    bins=[0, 40, 55, 70, 100],\n",
    "    labels = ['<40', '40-54', '55-69', '70+']\n",
    "    new_column = 'age_group'\n",
    ")\n",
    "print(\"3. Age groups created\")\n",
    "print(df_typed[['age', 'age_group']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create BMI categories\n",
    "df_typed = create_bins(\n",
    "    df_typed,\n",
    "    column = 'bmi',\n",
    "    bins=[0, 18.5, 24.9, 29.9, float('inf')],\n",
    "    labels = ['Underweight', 'Normal weight', 'Overweight', 'Obese'],\n",
    "    new_column = 'bmi_category'\n",
    ")\n",
    "# bins might be 0, 18.5, 25, 30, 100]\n",
    "\n",
    "print(\"4. BMI categories created\")\n",
    "print(df_typed[['bmi', 'bmi_category']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: String Cleaning (2 points)\n",
    "\n",
    "If there are any string columns that need cleaning:\n",
    "1. Convert to lowercase\n",
    "2. Strip whitespace\n",
    "3. Replace any placeholder values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: String cleaning\n",
    "string_cols = df_typed.select_dtypes(include=['object','category']).columns\n",
    "original_categories = df_typed.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "for col in string_cols:\n",
    "    df_typed[col] = (df_typed[col]\n",
    "                     .astype(str)\n",
    "                     .str.lower()\n",
    "                     .str.strip()\n",
    "                     .replace(['unknown', 'n/a', 'na', 'none', ''], np.nan ))\n",
    "    \n",
    "for col in original_categories:\n",
    "    df_typed[col] = df_typed[col].astype('category')\n",
    "    \n",
    "print(f\"Cleaned {len(string_cols)} columns: {list(string_cols)}\")\n",
    "print(f\" Restored {len(original_categories)} columns to category type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: One-Hot Encoding (5 points)\n",
    "\n",
    "Create dummy variables for categorical columns:\n",
    "1. One-hot encode 'intervention_group' using `pd.get_dummies()`\n",
    "2. One-hot encode 'site'\n",
    "3. Drop the original categorical columns\n",
    "4. Show the new shape and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: One-hot encoding\n",
    "# 1. one-hot encode 'intervention_group'\n",
    "intervention_dummies = pd.get_dummies(df_typed['intervention_group'], prefix='intervention')\n",
    "df_typed = pd.concat([df_typed, intervention_dummies], axis=1)\n",
    "print(f\"1. Created dummy variables: {list(intervention_dummies.columns)}\")\n",
    "print(df_typed[['intervention_group'] + list(intervention_dummies.columns)].head(10))\n",
    "\n",
    "# 2. one-hot encode 'site'\n",
    "site_dummies = pd.get_dummies(df_typed['site'], prefix='site')\n",
    "df_typed = pd.concat([df_typed, site_dummies], axis=1)\n",
    "print(f\"2. Created dummy variables: {list(site_dummies.columns)}\")\n",
    "print(df_typed[['site'] + list(site_dummies.columns)].head(10))\n",
    "\n",
    "# 3. Drop original categorical columns\n",
    "df_typed = df_typed.drop(columns=['intervention_group', 'site'])\n",
    "\n",
    "# 4. Show new shape and column names\n",
    "print(\"3. Original columns dropped\")\n",
    "print(f\"New DataFrame shape: {df_typed.shape}\")\n",
    "print(f\"Column names: {list(df_typed.columns.tolist())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Save Transformed Data\n",
    "\n",
    "Save the fully transformed dataset to `output/q6_transformed_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save transformed data\n",
    "# df_transformed.to_csv('output/q6_transformed_data.csv', index=False)\n",
    "df_typed.to_csv('output/q6_transformed_data.csv', index=False)\n",
    "\n",
    "print(\"Transformed data saved to output/q6_transformed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
