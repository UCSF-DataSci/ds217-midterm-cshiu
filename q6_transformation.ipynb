{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5, Question 6: Data Transformation\n",
    "\n",
    "**Points: 20**\n",
    "\n",
    "Transform and engineer features from the clinical trial dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run test on q3_data cleanup...\n",
      "Test DataFrame created: (5, 3)\n",
      "Test detect_missing: 2\n",
      "Test passed!\n",
      "Loaded 10000 patients\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import utilities\n",
    "from q3_data_utils import load_data, clean_data, transform_types, create_bins, fill_missing\n",
    "\n",
    "df = load_data('data/clinical_trial_raw.csv')\n",
    "print(f\"Loaded {len(df)} patients\")\n",
    "\n",
    "# Prewritten visualization functions for transformation analysis\n",
    "def plot_distribution(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a histogram of a numeric series.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with numeric data\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.hist(bins=30)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_value_counts(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a bar chart of value counts.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with value counts\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.plot(kind='bar')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Type Conversions (5 points)\n",
    "\n",
    "1. Convert 'enrollment_date' to datetime using the `transform_types()` utility\n",
    "2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "3. Ensure all numeric columns are proper numeric types\n",
    "4. Display the updated dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Data types before transformation:\n",
      "============================================================\n",
      "\n",
      "1. Converting enrollment_date to datetime...\n",
      " enrollment_date converted to datetime\n",
      "\n",
      "2. Converting categorical columns to category type...\n",
      " Categorical columns converted to category type\n",
      "\n",
      "3. Converting numeric columns to proper numeric type...\n",
      "Warning: Column 'weight' not found in DataFrame.\n",
      "Warning: Column 'height' not found in DataFrame.\n",
      " Numeric columns converted to proper numeric type\n",
      "\n",
      "4. Updated data types:\n",
      "patient_id                    object\n",
      "age                            int64\n",
      "sex                         category\n",
      "bmi                          float64\n",
      "enrollment_date       datetime64[ns]\n",
      "systolic_bp                  float64\n",
      "diastolic_bp                 float64\n",
      "cholesterol_total            float64\n",
      "cholesterol_hdl              float64\n",
      "cholesterol_ldl              float64\n",
      "glucose_fasting              float64\n",
      "site                        category\n",
      "intervention_group          category\n",
      "follow_up_months               int64\n",
      "adverse_events                 int64\n",
      "outcome_cvd                   object\n",
      "adherence_pct                float64\n",
      "dropout                       object\n",
      "dtype: object\n",
      "\n",
      "Summary of type changes:\n",
      " Datetime columns: 1\n",
      " Categorical columns: 3\n",
      " Numeric columns: 11\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO: Type conversions\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Data types before transformation:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# 1. Use transform_types() to convert enrollment_date to datetime\n",
    "print(\"1. Converting enrollment_date to datetime...\")\n",
    "type_map = {'enrollment_date': 'datetime'}\n",
    "df_typed = transform_types(df, type_map)\n",
    "print(\" enrollment_date converted to datetime\")\n",
    "print()\n",
    "\n",
    "# 2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "print(\"2. Converting categorical columns to category type...\")\n",
    "categorical_cols = {\n",
    "    'site': 'category',\n",
    "    'intervention_group': 'category',\n",
    "    'sex': 'category'\n",
    "}\n",
    "df_typed = transform_types(df_typed, categorical_cols)\n",
    "print(\" Categorical columns converted to category type\")\n",
    "print()\n",
    "\n",
    "# 3. Ensure all numeric columns are proper numeric types\n",
    "print(\"3. Converting numeric columns to proper numeric type...\")\n",
    "numeric_map = {\n",
    "    'age': 'numeric',\n",
    "    'bmi': 'numeric',\n",
    "    'weight': 'numeric',\n",
    "    'height': 'numeric',\n",
    "    'cholesterol_total': 'numeric',\n",
    "    'systolic_bp': 'numeric',\n",
    "    'diastolic_bp': 'numeric'\n",
    "}\n",
    "df_typed = transform_types(df_typed, numeric_map)\n",
    "print(\" Numeric columns converted to proper numeric type\")\n",
    "print()\n",
    "\n",
    "# 4. Display the updated dtypes using df.dtypes\n",
    "print(\"4. Updated data types:\")\n",
    "print(df_typed.dtypes)\n",
    "print()\n",
    "\n",
    "\n",
    "# Summary of changes\n",
    "print(\"Summary of type changes:\")\n",
    "print(f\" Datetime columns: {(df_typed.dtypes == 'datetime64[ns]').sum()}\")\n",
    "print(f\" Categorical columns: {(df_typed.dtypes == 'category').sum()}\")\n",
    "print(f\" Numeric columns: {(df_typed.select_dtypes(include=[np.number]).shape[1])}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering (8 points)\n",
    "\n",
    "Create these new calculated columns:\n",
    "\n",
    "1. `cholesterol_ratio` = cholesterol_ldl / cholesterol_hdl\n",
    "2. `bp_category` = categorize systolic BP:\n",
    "   - 'Normal': < 120\n",
    "   - 'Elevated': 120-129\n",
    "   - 'High': >= 130\n",
    "3. `age_group` using `create_bins()` utility:\n",
    "   - Bins: [0, 40, 55, 70, 100]\n",
    "   - Labels: ['<40', '40-54', '55-69', '70+']\n",
    "4. `bmi_category` using standard BMI categories:\n",
    "   - Underweight: <18.5\n",
    "   - Normal: 18.5-24.9\n",
    "   - Overweight: 25-29.9\n",
    "   - Obese: >=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Creating cholesterol ratio column...\n",
      "   Cholesterol ratio = cholesterol_ldl / cholesterol_hdl\n",
      "   cholesterol_ldl  cholesterol_hdl  cholesterol_ratio\n",
      "0             41.0             55.0           0.745455\n",
      "1            107.0             58.0           1.844828\n",
      "2             82.0             56.0           1.464286\n",
      "3            104.0             56.0           1.857143\n",
      "4             75.0             78.0           0.961538\n",
      "5             99.0             54.0           1.833333\n",
      "6            113.0             62.0           1.822581\n",
      "7             94.0             60.0           1.566667\n",
      "8             89.0             62.0           1.435484\n",
      "9             97.0             77.0           1.259740\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate cholesterol ratio\n",
    "\n",
    "print(\"1. Creating cholesterol ratio column...\")\n",
    "df_typed['cholesterol_ratio'] = df_typed['cholesterol_ldl'] / df_typed['cholesterol_hdl']\n",
    "print(\"   Cholesterol ratio = cholesterol_ldl / cholesterol_hdl\")\n",
    "print(df_typed[['cholesterol_ldl', 'cholesterol_hdl', 'cholesterol_ratio']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP categories created\n",
      "\n",
      "   systolic_bp bp_category\n",
      "0        123.0    Elevated\n",
      "1        139.0        High\n",
      "2        123.0    Elevated\n",
      "3        116.0      Normal\n",
      "4         97.0      Normal\n",
      "5        116.0      Normal\n",
      "6        133.0        High\n",
      "7        111.0      Normal\n",
      "8          NaN        High\n",
      "9        128.0    Elevated\n"
     ]
    }
   ],
   "source": [
    "# TODO: Categorize blood pressure\n",
    "\n",
    "df_typed['bp_category'] = np.where(\n",
    "    df_typed['systolic_bp'] < 120, 'Normal',\n",
    "    np.where(\n",
    "        (df_typed['systolic_bp'] >= 120) & (df_typed['systolic_bp'] < 130), 'Elevated',\n",
    "        'High'\n",
    "    )\n",
    ")\n",
    "print(\"BP categories created\\n\")\n",
    "print(df_typed[['systolic_bp', 'bp_category']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The `create_bins()` function has an optional `new_column` parameter. If you don't specify it, the new column will be named `{original_column}_binned`. You can use `new_column='age_group'` to give it a custom name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create age groups\n",
    "df_typed = create_bins(\n",
    "    df_typed,\n",
    "    column = 'age',\n",
    "    bins=[0, 40, 55, 70, 100],\n",
    "    labels = ['<40', '40-54', '55-69', '70+']\n",
    "    new_column = 'age_group'\n",
    ")\n",
    "print(\"3. Age groups created\")\n",
    "print(df_typed[['age', 'age_group']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create BMI categories\n",
    "df_typed = create_bins(\n",
    "    df_typed,\n",
    "    column = 'bmi',\n",
    "    bins=[0, 18.5, 24.9, 29.9, float('inf')],\n",
    "    labels = ['Underweight', 'Normal weight', 'Overweight', 'Obese'],\n",
    "    new_column = 'bmi_category'\n",
    ")\n",
    "# bins might be 0, 18.5, 25, 30, 100]\n",
    "\n",
    "print(\"4. BMI categories created\")\n",
    "print(df_typed[['bmi', 'bmi_category']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: String Cleaning (2 points)\n",
    "\n",
    "If there are any string columns that need cleaning:\n",
    "1. Convert to lowercase\n",
    "2. Strip whitespace\n",
    "3. Replace any placeholder values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: String cleaning\n",
    "string_cols = df_typed.select_dtypes(include=['object','category']).columns\n",
    "original_categories = df_typed.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "for col in string_cols:\n",
    "    df_typed[col] = (df_typed[col]\n",
    "                     .astype(str)\n",
    "                     .str.lower()\n",
    "                     .str.strip()\n",
    "                     .replace(['unknown', 'n/a', 'na', 'none', ''], np.nan ))\n",
    "    \n",
    "for col in original_categories:\n",
    "    df_typed[col] = df_typed[col].astype('category')\n",
    "    \n",
    "print(f\"Cleaned {len(string_cols)} columns: {list(string_cols)}\")\n",
    "print(f\" Restored {len(original_categories)} columns to category type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: One-Hot Encoding (5 points)\n",
    "\n",
    "Create dummy variables for categorical columns:\n",
    "1. One-hot encode 'intervention_group' using `pd.get_dummies()`\n",
    "2. One-hot encode 'site'\n",
    "3. Drop the original categorical columns\n",
    "4. Show the new shape and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: One-hot encoding\n",
    "# 1. one-hot encode 'intervention_group'\n",
    "intervention_dummies = pd.get_dummies(df_typed['intervention_group'], prefix='intervention')\n",
    "df_typed = pd.concat([df_typed, intervention_dummies], axis=1)\n",
    "print(f\"1. Created dummy variables: {list(intervention_dummies.columns)}\")\n",
    "print(df_typed[['intervention_group'] + list(intervention_dummies.columns)].head(10))\n",
    "\n",
    "# 2. one-hot encode 'site'\n",
    "site_dummies = pd.get_dummies(df_typed['site'], prefix='site')\n",
    "df_typed = pd.concat([df_typed, site_dummies], axis=1)\n",
    "print(f\"2. Created dummy variables: {list(site_dummies.columns)}\")\n",
    "print(df_typed[['site'] + list(site_dummies.columns)].head(10))\n",
    "\n",
    "# 3. Drop original categorical columns\n",
    "df_typed = df_typed.drop(columns=['intervention_group', 'site'])\n",
    "\n",
    "# 4. Show new shape and column names\n",
    "print(\"3. Original columns dropped\")\n",
    "print(f\"New DataFrame shape: {df_typed.shape}\")\n",
    "print(f\"Column names: {list(df_typed.columns.tolist())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Save Transformed Data\n",
    "\n",
    "Save the fully transformed dataset to `output/q6_transformed_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save transformed data\n",
    "# df_transformed.to_csv('output/q6_transformed_data.csv', index=False)\n",
    "df_typed.to_csv('output/q6_transformed_data.csv', index=False)\n",
    "\n",
    "print(\"Transformed data saved to output/q6_transformed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
