{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5, Question 6: Data Transformation\n",
    "\n",
    "**Points: 20**\n",
    "\n",
    "Transform and engineer features from the clinical trial dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 patients\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import utilities\n",
    "from q3_data_utils import load_data, clean_data, transform_types, create_bins, fill_missing\n",
    "\n",
    "df = load_data('data/clinical_trial_raw.csv')\n",
    "print(f\"Loaded {len(df)} patients\")\n",
    "\n",
    "# Prewritten visualization functions for transformation analysis\n",
    "def plot_distribution(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a histogram of a numeric series.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with numeric data\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.hist(bins=30)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_value_counts(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a bar chart of value counts.\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series with value counts\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.plot(kind='bar')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Type Conversions (5 points)\n",
    "\n",
    "1. Convert 'enrollment_date' to datetime using the `transform_types()` utility\n",
    "2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "3. Ensure all numeric columns are proper numeric types\n",
    "4. Display the updated dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Data types before transformation:\n",
      "============================================================\n",
      "\n",
      "1. Converting enrollment_date to datetime...\n",
      " enrollment_date converted to datetime\n",
      "\n",
      "2. Converting categorical columns to category type...\n",
      " Categorical columns converted to category type\n",
      "\n",
      "3. Converting numeric columns to proper numeric type...\n",
      "Warning: Column 'weight' not found in DataFrame.\n",
      "Warning: Column 'height' not found in DataFrame.\n",
      " Numeric columns converted to proper numeric type\n",
      "\n",
      "4. Updated data types:\n",
      "patient_id                    object\n",
      "age                            int64\n",
      "sex                         category\n",
      "bmi                          float64\n",
      "enrollment_date       datetime64[ns]\n",
      "systolic_bp                  float64\n",
      "diastolic_bp                 float64\n",
      "cholesterol_total            float64\n",
      "cholesterol_hdl              float64\n",
      "cholesterol_ldl              float64\n",
      "glucose_fasting              float64\n",
      "site                        category\n",
      "intervention_group          category\n",
      "follow_up_months               int64\n",
      "adverse_events                 int64\n",
      "outcome_cvd                   object\n",
      "adherence_pct                float64\n",
      "dropout                       object\n",
      "dtype: object\n",
      "\n",
      "Summary of type changes:\n",
      " Datetime columns: 1\n",
      " Categorical columns: 3\n",
      " Numeric columns: 11\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO: Type conversions\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Data types before transformation:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# 1. Use transform_types() to convert enrollment_date to datetime\n",
    "print(\"1. Converting enrollment_date to datetime...\")\n",
    "type_map = {'enrollment_date': 'datetime'}\n",
    "df_typed = transform_types(df, type_map)\n",
    "print(\" enrollment_date converted to datetime\")\n",
    "print()\n",
    "\n",
    "# 2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "print(\"2. Converting categorical columns to category type...\")\n",
    "categorical_cols = {\n",
    "    'site': 'category',\n",
    "    'intervention_group': 'category',\n",
    "    'sex': 'category'\n",
    "}\n",
    "df_typed = transform_types(df_typed, categorical_cols)\n",
    "print(\" Categorical columns converted to category type\")\n",
    "print()\n",
    "\n",
    "# 3. Ensure all numeric columns are proper numeric types\n",
    "print(\"3. Converting numeric columns to proper numeric type...\")\n",
    "numeric_map = {\n",
    "    'age': 'numeric',\n",
    "    'bmi': 'numeric',\n",
    "    'weight': 'numeric',\n",
    "    'height': 'numeric',\n",
    "    'cholesterol_total': 'numeric',\n",
    "    'systolic_bp': 'numeric',\n",
    "    'diastolic_bp': 'numeric'\n",
    "}\n",
    "df_typed = transform_types(df_typed, numeric_map)\n",
    "print(\" Numeric columns converted to proper numeric type\")\n",
    "print()\n",
    "\n",
    "# 4. Display the updated dtypes using df.dtypes\n",
    "print(\"4. Updated data types:\")\n",
    "print(df_typed.dtypes)\n",
    "print()\n",
    "\n",
    "\n",
    "# Summary of changes\n",
    "print(\"Summary of type changes:\")\n",
    "print(f\" Datetime columns: {(df_typed.dtypes == 'datetime64[ns]').sum()}\")\n",
    "print(f\" Categorical columns: {(df_typed.dtypes == 'category').sum()}\")\n",
    "print(f\" Numeric columns: {(df_typed.select_dtypes(include=[np.number]).shape[1])}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering (8 points)\n",
    "\n",
    "Create these new calculated columns:\n",
    "\n",
    "1. `cholesterol_ratio` = cholesterol_ldl / cholesterol_hdl\n",
    "2. `bp_category` = categorize systolic BP:\n",
    "   - 'Normal': < 120\n",
    "   - 'Elevated': 120-129\n",
    "   - 'High': >= 130\n",
    "3. `age_group` using `create_bins()` utility:\n",
    "   - Bins: [0, 40, 55, 70, 100]\n",
    "   - Labels: ['<40', '40-54', '55-69', '70+']\n",
    "4. `bmi_category` using standard BMI categories:\n",
    "   - Underweight: <18.5\n",
    "   - Normal: 18.5-24.9\n",
    "   - Overweight: 25-29.9\n",
    "   - Obese: >=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Creating cholesterol ratio column...\n",
      "   Cholesterol ratio = cholesterol_ldl / cholesterol_hdl\n",
      "   cholesterol_ldl  cholesterol_hdl  cholesterol_ratio\n",
      "0             41.0             55.0           0.745455\n",
      "1            107.0             58.0           1.844828\n",
      "2             82.0             56.0           1.464286\n",
      "3            104.0             56.0           1.857143\n",
      "4             75.0             78.0           0.961538\n",
      "5             99.0             54.0           1.833333\n",
      "6            113.0             62.0           1.822581\n",
      "7             94.0             60.0           1.566667\n",
      "8             89.0             62.0           1.435484\n",
      "9             97.0             77.0           1.259740\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate cholesterol ratio\n",
    "\n",
    "print(\"1. Creating cholesterol ratio column...\")\n",
    "df_typed['cholesterol_ratio'] = df_typed['cholesterol_ldl'] / df_typed['cholesterol_hdl']\n",
    "print(\"   Cholesterol ratio = cholesterol_ldl / cholesterol_hdl\")\n",
    "print(df_typed[['cholesterol_ldl', 'cholesterol_hdl', 'cholesterol_ratio']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP categories created\n",
      "\n",
      "   systolic_bp bp_category\n",
      "0        123.0    Elevated\n",
      "1        139.0        High\n",
      "2        123.0    Elevated\n",
      "3        116.0      Normal\n",
      "4         97.0      Normal\n",
      "5        116.0      Normal\n",
      "6        133.0        High\n",
      "7        111.0      Normal\n",
      "8          NaN        High\n",
      "9        128.0    Elevated\n"
     ]
    }
   ],
   "source": [
    "# TODO: Categorize blood pressure\n",
    "\n",
    "df_typed['bp_category'] = np.where(\n",
    "    df_typed['systolic_bp'] < 120, 'Normal',\n",
    "    np.where(\n",
    "        (df_typed['systolic_bp'] >= 120) & (df_typed['systolic_bp'] < 130), 'Elevated',\n",
    "        'High'\n",
    "    )\n",
    ")\n",
    "print(\"BP categories created\\n\")\n",
    "print(df_typed[['systolic_bp', 'bp_category']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The `create_bins()` function has an optional `new_column` parameter. If you don't specify it, the new column will be named `{original_column}_binned`. You can use `new_column='age_group'` to give it a custom name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Age groups created\n",
      "   age age_group\n",
      "0   80       70+\n",
      "1   80       70+\n",
      "2   82       70+\n",
      "3   95       70+\n",
      "4   95       70+\n",
      "5   78       70+\n",
      "6   84       70+\n",
      "7   70       70+\n",
      "8   92       70+\n",
      "9   75       70+\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create age groups\n",
    "df_typed = create_bins(\n",
    "    df_typed,\n",
    "    column = 'age',\n",
    "    bins=[0, 39, 54, 69, 100],\n",
    "    labels = ['<40', '40-54', '55-69', '70+'],\n",
    "    new_column = 'age_group'\n",
    ")\n",
    "print(\"3. Age groups created\")\n",
    "print(df_typed[['age', 'age_group']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cleaning BMI: 9374\n",
      "\n",
      "4. BMI categories created\n",
      "\n",
      "     bmi   bmi_category\n",
      "0   29.3     Overweight\n",
      "3   25.4     Overweight\n",
      "5   26.8     Overweight\n",
      "6   25.4     Overweight\n",
      "7   24.7  Normal weight\n",
      "8   26.9     Overweight\n",
      "9   21.1  Normal weight\n",
      "10  23.5  Normal weight\n",
      "12  28.0     Overweight\n",
      "13  21.1  Normal weight\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create BMI categories\n",
    "\n",
    "# First, drop missing values or negative values\n",
    "\n",
    "df_typed = df_typed[df_typed['bmi'].notna()]\n",
    "df_typed = df_typed[df_typed['bmi'] != -1.0]\n",
    "\n",
    "print(f\"Rows after cleaning BMI: {len(df_typed)}\\n\")\n",
    "\n",
    "df_typed = create_bins(\n",
    "    df_typed,\n",
    "    column = 'bmi',\n",
    "    bins=[0, 18.5, 24.9, 29.9, float('inf')],\n",
    "    labels = ['Underweight', 'Normal weight', 'Overweight', 'Obese'],\n",
    "    new_column = 'bmi_category'\n",
    ")\n",
    "# bins might be 0, 18.5, 25, 30, 100]\n",
    "\n",
    "print(\"4. BMI categories created\\n\")\n",
    "print(df_typed[['bmi', 'bmi_category']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: String Cleaning (2 points)\n",
    "\n",
    "If there are any string columns that need cleaning:\n",
    "1. Convert to lowercase\n",
    "2. Strip whitespace\n",
    "3. Replace any placeholder values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned 9 columns: ['patient_id', 'sex', 'site', 'intervention_group', 'outcome_cvd', 'dropout', 'bp_category', 'age_group', 'bmi_category']\n",
      "\n",
      " Restored 5 columns to category type\n"
     ]
    }
   ],
   "source": [
    "# TODO: String cleaning\n",
    "string_cols = df_typed.select_dtypes(include=['object','category']).columns\n",
    "original_categories = df_typed.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "for col in string_cols:\n",
    "    df_typed[col] = (df_typed[col]\n",
    "                     .astype(str)\n",
    "                     .str.lower()\n",
    "                     .str.strip()\n",
    "                     .replace(['unknown', 'n/a', 'na', 'none', ''], np.nan ))\n",
    "    \n",
    "for col in original_categories:\n",
    "    df_typed[col] = df_typed[col].astype('category')\n",
    "    \n",
    "print(f\"Cleaned {len(string_cols)} columns: {list(string_cols)}\\n\")\n",
    "print(f\" Restored {len(original_categories)} columns to category type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: One-Hot Encoding (5 points)\n",
    "\n",
    "Create dummy variables for categorical columns:\n",
    "1. One-hot encode 'intervention_group' using `pd.get_dummies()`\n",
    "2. One-hot encode 'site'\n",
    "3. Drop the original categorical columns\n",
    "4. Show the new shape and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Created dummy variables: ['intervention_contrl', 'intervention_control', 'intervention_treatmen a', 'intervention_treatment  b', 'intervention_treatment a', 'intervention_treatment b', 'intervention_treatmenta']\n",
      "   intervention_group  intervention_contrl  intervention_control  \\\n",
      "0             control                False                  True   \n",
      "3         treatment b                False                 False   \n",
      "5          treatmenta                False                 False   \n",
      "6         treatment a                False                 False   \n",
      "7         treatment a                False                 False   \n",
      "8             control                False                  True   \n",
      "9         treatment b                False                 False   \n",
      "10            control                False                  True   \n",
      "12        treatment a                False                 False   \n",
      "13            control                False                  True   \n",
      "\n",
      "    intervention_treatmen a  intervention_treatment  b  \\\n",
      "0                     False                      False   \n",
      "3                     False                      False   \n",
      "5                     False                      False   \n",
      "6                     False                      False   \n",
      "7                     False                      False   \n",
      "8                     False                      False   \n",
      "9                     False                      False   \n",
      "10                    False                      False   \n",
      "12                    False                      False   \n",
      "13                    False                      False   \n",
      "\n",
      "    intervention_treatment a  intervention_treatment b  \\\n",
      "0                      False                     False   \n",
      "3                      False                      True   \n",
      "5                      False                     False   \n",
      "6                       True                     False   \n",
      "7                       True                     False   \n",
      "8                      False                     False   \n",
      "9                      False                      True   \n",
      "10                     False                     False   \n",
      "12                      True                     False   \n",
      "13                     False                     False   \n",
      "\n",
      "    intervention_treatmenta  \n",
      "0                     False  \n",
      "3                     False  \n",
      "5                      True  \n",
      "6                     False  \n",
      "7                     False  \n",
      "8                     False  \n",
      "9                     False  \n",
      "10                    False  \n",
      "12                    False  \n",
      "13                    False  \n",
      "2. Created dummy variables: ['site_site  a', 'site_site a', 'site_site b', 'site_site c', 'site_site d', 'site_site e', 'site_site_d']\n",
      "      site  site_site  a  site_site a  site_site b  site_site c  site_site d  \\\n",
      "0   site b         False        False         True        False        False   \n",
      "3   site d         False        False        False        False         True   \n",
      "5   site a         False         True        False        False        False   \n",
      "6   site a         False         True        False        False        False   \n",
      "7   site b         False        False         True        False        False   \n",
      "8   site a         False         True        False        False        False   \n",
      "9   site a         False         True        False        False        False   \n",
      "10  site a         False         True        False        False        False   \n",
      "12  site b         False        False         True        False        False   \n",
      "13  site e         False        False        False        False        False   \n",
      "\n",
      "    site_site e  site_site_d  \n",
      "0         False        False  \n",
      "3         False        False  \n",
      "5         False        False  \n",
      "6         False        False  \n",
      "7         False        False  \n",
      "8         False        False  \n",
      "9         False        False  \n",
      "10        False        False  \n",
      "12        False        False  \n",
      "13         True        False  \n",
      "3. Original columns dropped\n",
      "New DataFrame shape: (9374, 34)\n",
      "Column names: ['patient_id', 'age', 'sex', 'bmi', 'enrollment_date', 'systolic_bp', 'diastolic_bp', 'cholesterol_total', 'cholesterol_hdl', 'cholesterol_ldl', 'glucose_fasting', 'follow_up_months', 'adverse_events', 'outcome_cvd', 'adherence_pct', 'dropout', 'cholesterol_ratio', 'bp_category', 'age_group', 'bmi_category', 'intervention_contrl', 'intervention_control', 'intervention_treatmen a', 'intervention_treatment  b', 'intervention_treatment a', 'intervention_treatment b', 'intervention_treatmenta', 'site_site  a', 'site_site a', 'site_site b', 'site_site c', 'site_site d', 'site_site e', 'site_site_d']\n"
     ]
    }
   ],
   "source": [
    "# TODO: One-hot encoding\n",
    "# 1. one-hot encode 'intervention_group'\n",
    "intervention_dummies = pd.get_dummies(df_typed['intervention_group'], prefix='intervention')\n",
    "df_typed = pd.concat([df_typed, intervention_dummies], axis=1)\n",
    "print(f\"1. Created dummy variables: {list(intervention_dummies.columns)}\")\n",
    "print(df_typed[['intervention_group'] + list(intervention_dummies.columns)].head(10))\n",
    "\n",
    "# 2. one-hot encode 'site'\n",
    "site_dummies = pd.get_dummies(df_typed['site'], prefix='site')\n",
    "df_typed = pd.concat([df_typed, site_dummies], axis=1)\n",
    "print(f\"2. Created dummy variables: {list(site_dummies.columns)}\")\n",
    "print(df_typed[['site'] + list(site_dummies.columns)].head(10))\n",
    "\n",
    "# 3. Drop original categorical columns\n",
    "df_typed = df_typed.drop(columns=['intervention_group', 'site'])\n",
    "\n",
    "# 4. Show new shape and column names\n",
    "print(\"3. Original columns dropped\")\n",
    "print(f\"New DataFrame shape: {df_typed.shape}\")\n",
    "print(f\"Column names: {list(df_typed.columns.tolist())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Save Transformed Data\n",
    "\n",
    "Save the fully transformed dataset to `output/q6_transformed_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data saved to output/q6_transformed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# TODO: Save transformed data\n",
    "# df_transformed.to_csv('output/q6_transformed_data.csv', index=False)\n",
    "df_typed.to_csv('output/q6_transformed_data.csv', index=False)\n",
    "\n",
    "print(\"Transformed data saved to output/q6_transformed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
